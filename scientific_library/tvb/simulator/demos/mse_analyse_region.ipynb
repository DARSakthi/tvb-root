{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Demo use case: showing TVB flexibility. \n",
    "Set up a complete simulation and analysis  scheme imitating the exploratory workflow in studies from the  literature.\n",
    "See Fig. 9 in [1]\n",
    "The underlying idea is is based on [2] and [3] and probably should aim to finally\n",
    "reproduce [4].\n",
    "\n",
    "Background: \n",
    "    This demo should not be taken as an attempt to reproduce experimental results.\n",
    "    It lacks from solid theoretical foundations. The background info is only\n",
    "    to give a more scientifically interesting scenario and justify the choices\n",
    "    of the observed nodes and such. \n",
    "    \n",
    "    When thinking about stimulation paradigms in the context of a whole brain \n",
    "    experimental protocol, the first ones that jump to my mind: \n",
    "        - face/object recognition.\n",
    "        - visually evoked potentials (VEP).\n",
    "        - trans-cranial magnetic stimulation (TMS).\n",
    "        \n",
    "    \n",
    "    The constraints: \n",
    "        - Make a demo as simple as possible and thus not including the sub-cortical\n",
    "          structures. Many sensory inputs go first through the thalamus and then\n",
    "          its projections reach the cortex. \n",
    "        - Directly stimulating the cortex with an arbitrary stimulus. Intensity \n",
    "          units are arbitrary.   \n",
    "    \n",
    "    Finally, the stimulus is a Pulse Train with a frequency repetition of 4Hz. \n",
    "    This low value is the frequency used for flashing stimuli.  Visual stimuli \n",
    "    stimulate both primary visual and secondary visual areas (V1, V2)\n",
    "    \n",
    "    Recordings from scalp: the mid-occipital electrode location (OZ) as in [2] and\n",
    "    because we are stimulating the visual cortex.  \n",
    "\n",
    "Steps: \n",
    "    1. Set up basic simulation components\n",
    "    2. Build a stimulation pattern\n",
    "    3. Generate simulated data with and without stimulation. \n",
    "    4. Compute MSE\n",
    "    5. Plot results\n",
    "\n",
    "Objective:\n",
    "   Compare the complexity in the resting state against evoked activity, based\n",
    "   on MSE computed on the EEG time-series from sensor Oz (occipital region).\n",
    "   The scientific motivation is (would be) to evaluate how complexity changes as \n",
    "   a function of stimulation.\n",
    "\n",
    "    \n",
    "Sim Info: \n",
    "    Node indices corresponding to left  temporal and visual cortices (30:36).\n",
    "    - assuming the Connectivity matrix is the default with 74 nodes.\n",
    "\n",
    "    EEG electrode indice corresponding to O1, O2 and Oz (8, 9, 60).\n",
    "    The EEG sensors represent 62 scalp electrodes distributed according to the \n",
    "    10â€“20 system.\n",
    "\n",
    "[1] Sanz Leon P.; Woodman; M.; Knock; S.; (...); Jirsa, V. The Virtual Brain: a\n",
    "    simulator of primate brain dynamics. Frontiers in Neuroinformatics.\n",
    "\n",
    "[2] McIntosh, A.; Kovacevic, N.; Lippe, S.; Garrett, D.; Grady, C. & Jirsa, V. \n",
    "    The Development of a Noisy Brain Archives Italiennes de Biologie, 2010, 148, -\n",
    "[3] Schneider, G. E. Two visual systems. Science, 1969, 163, 895-902\n",
    "\n",
    "Recommended:\n",
    "\n",
    "[4] David, O. & Friston, K. J. A neural mass model for MEG/EEG: coupling and \n",
    "neuronal dynamics. Neuroimage.\n",
    "\n",
    "\n",
    "Total runtime ~ 10 min on Intel Xeon(R) CPU W3520 @ 2.67GHz \n",
    "\n",
    "SSVEP: Steady State Visually Evoked Potentials.  There is a number of points to be \n",
    "determined. Selection of electrodes and stimulating frequencies, feature extraction \n",
    "(MSE?), spectral methods. Lead position is important, however for VEPs, normally \n",
    "electrode at the occipital region are selected.\n",
    "\n",
    "TCc --> central temporal cortex\t\t\t\t\t\t\t\t\n",
    "TCi --> inferior temporal cortex\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tvb.simulator.lab import *\n",
    "import matplotlib.gridspec as gridspec\n",
    "from tvb.datatypes.projections import ProjectionSurfaceEEG\n",
    "from tvb.datatypes.sensors import SensorsEEG\n",
    "from tvb.datatypes.region_mapping import RegionMapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lV1, lV2,\n",
    "nodes = [35, 36]\n",
    "\n",
    "# O1, O2, Oz\n",
    "eeg_nodes = [8, 9, 60]\n",
    "\n",
    "# discard transients for analysis\n",
    "start = 2048 * 2 - 128  # at 1 second\n",
    "# for pretty pictures\n",
    "stop = 2048 * 5 - 64  # 2.5 second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Set up a simulator  instance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def configure_simulation(stimulate):\n",
    "    \"\"\"\n",
    "    Set up a Simulator object (a brain network model and all its individual \n",
    "    components + output modalities)\n",
    "    \"\"\"\n",
    "    # eeg projection matrix from regions to sensors\n",
    "    LOG.info(\"Reading sensors info\")\n",
    "    \n",
    "    pr = ProjectionSurfaceEEG(load_default=True)\n",
    "    sensors = SensorsEEG.from_file(source_file=\"eeg-brainstorm-65.txt\")\n",
    "    rm = RegionMapping(load_default=True)\n",
    "\n",
    "    #Initialise a Model, Connectivity, Coupling, set speed.\n",
    "    oscilator = models.Generic2dOscillator(a=-0.5, b=-10., c=0.0, d=0.02)\n",
    "\n",
    "    white_matter = connectivity.Connectivity(load_default=True)\n",
    "    white_matter.speed = numpy.array([4.0])\n",
    "    white_matter_coupling = coupling.Linear(a=0.042)\n",
    "\n",
    "    #Initialise an Integrator\n",
    "    hiss = noise.Additive(nsig=numpy.array([0.00]))  # nsigm 0.015\n",
    "    heunint = integrators.HeunStochastic(dt=2 ** -6, noise=hiss)\n",
    "\n",
    "    # Recording techniques\n",
    "    what_to_watch = (monitors.TemporalAverage(period=1e3 / 4096.),\n",
    "                     monitors.EEG(projection=pr, sensors=sensors, region_mapping=rm, period=1e3 / 4096.))\n",
    "    # Stimulation paradigm\n",
    "    if stimulate:\n",
    "        stimulus = build_stimulus(white_matter)\n",
    "    else:\n",
    "        stimulus = None\n",
    "\n",
    "    #Initialise a Simulator -- Model, Connectivity, Integrator, and Monitors.\n",
    "    sim = simulator.Simulator(model=oscilator, connectivity=white_matter, coupling=white_matter_coupling,\n",
    "                              integrator=heunint, monitors=what_to_watch, stimulus=stimulus)\n",
    "    sim.configure()\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_simulation(sim):\n",
    "    LOG.info(\"Starting simulation...\")\n",
    "    #Perform the simulation\n",
    "    tavg_data = []\n",
    "    tavg_time = []\n",
    "    eeg_data = []\n",
    "    eeg_time = []\n",
    "\n",
    "    for tavg, eeg in sim(simulation_length=2 ** 12):\n",
    "    # approx 4 sec\n",
    "        if not tavg is None:\n",
    "            tavg_time.append(tavg[0])\n",
    "            tavg_data.append(tavg[1])\n",
    "\n",
    "        if not eeg is None:\n",
    "            eeg_time.append(eeg[0])\n",
    "            eeg_data.append(eeg[1])\n",
    "\n",
    "    LOG.info(\"Finished simulation.\")\n",
    "    return tavg_data, tavg_time, eeg_data, eeg_time, sim.stimulus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_stimulus(white_matter):\n",
    "    \"\"\"\n",
    "    Build a rectangular pulse train using an Equation datatype\n",
    "    \"\"\"\n",
    "\n",
    "    # access the region indices\n",
    "    white_matter.configure()\n",
    "\n",
    "    # specify weights for regions receiving stimulation  \n",
    "    weighting = numpy.zeros((white_matter.number_of_regions, 1))\n",
    "    weighting[nodes] = numpy.array([3.5, 0.0])[:, numpy.newaxis]\n",
    "\n",
    "    eqn_t = equations.PulseTrain()\n",
    "    eqn_t.parameters[\"onset\"] = 1000.0  # ms\n",
    "    eqn_t.parameters[\"tau\"] = 5.0    # ms\n",
    "    eqn_t.parameters[\"T\"] = 750.  # ms --> 0.0015kHz repetition frequency\n",
    "\n",
    "    stimulus = patterns.StimuliRegion(temporal=eqn_t, connectivity=white_matter, weight=weighting)\n",
    "    return stimulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_mse(xs_data, ys_data):\n",
    "    \"\"\"\n",
    "    Not trying to be smart. Only computing MSE for two different time series.\n",
    "    e.g\n",
    "    x: resting state eeg\n",
    "    y: evoked activity eeg\n",
    "    \"\"\"\n",
    "    from tvb.analyzers.info import sampen\n",
    "\n",
    "    x = numpy.array(xs_data)\n",
    "    y = numpy.array(ys_data)\n",
    "\n",
    "    sampen_x = sampen(x[2048:, 0, eeg_nodes[2], 0], r=.15, taus=numpy.r_[4:13], qse=False, m=2)\n",
    "    sampen_y = sampen(y[2048:, 0, eeg_nodes[2], 0], r=.15, taus=numpy.r_[4:13], qse=False, m=2)\n",
    "\n",
    "    return sampen_x, sampen_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_data(tavg_data, eeg_data, tavg_time, eeg_time, stimulus=None):\n",
    "    \"\"\"\n",
    "    Save simulated data\n",
    "    \"\"\"\n",
    "\n",
    "    TAVG = numpy.array(tavg_data)\n",
    "    EEG = numpy.array(eeg_data)\n",
    "\n",
    "    if stimulus is None:\n",
    "        FILE_NAME = \"rs_tavg_data_region_4s_2048Hz.npy\"\n",
    "        LOG.info(\"Saving array to %s...\" % FILE_NAME)\n",
    "        numpy.save(FILE_NAME, TAVG)\n",
    "\n",
    "        FILE_NAME = \"rs_eeg_data_region_4s_2048Hz.npy\"\n",
    "        LOG.info(\"Saving array to %s...\" % FILE_NAME)\n",
    "        numpy.save(FILE_NAME, EEG)\n",
    "\n",
    "    else:\n",
    "        FILE_NAME = \"stim_eeg_data_region_4s_2048Hz.npy\"\n",
    "        LOG.info(\"Saving array to %s...\" % FILE_NAME)\n",
    "        numpy.save(FILE_NAME, EEG)\n",
    "\n",
    "        FILE_NAME = \"stim_tavg_data_region_4s_2048Hz.npy\"\n",
    "        LOG.info(\"Saving array to %s...\" % FILE_NAME)\n",
    "        numpy.save(FILE_NAME, TAVG)\n",
    "\n",
    "        FILE_NAME = \"stim_pattern_data_region_4s.npy\"\n",
    "        LOG.info(\"Saving array to %s...\" % FILE_NAME)\n",
    "        numpy.save(FILE_NAME, stimulus.temporal.pattern)\n",
    "\n",
    "    FILE_NAME = \"time_tavg_data_region_4s_2048Hz.npy\"\n",
    "    LOG.info(\"Saving array to %s...\" % FILE_NAME)\n",
    "    numpy.save(FILE_NAME, numpy.array(tavg_time))\n",
    "\n",
    "    FILE_NAME = \"time_eeg_data_region_4s_2048Hz.npy\"\n",
    "    LOG.info(\"Saving array to %s...\" % FILE_NAME)\n",
    "    numpy.save(FILE_NAME, numpy.array(eeg_time))\n",
    "\n",
    "    # I'm assuming both tavg and eeg time vectors have the tpts sampled at \n",
    "    # the same frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_figure(se_x, se_y, eeg_data, tavg_data, rseeg, rstavg, pattern, nodes, eeg_nodes, time):\n",
    "    \"\"\"\n",
    "    Generate figure as shown in [1].\n",
    "    se_x: mse estimates for resting state like\n",
    "    se_y: mse estimates for evoked activity\n",
    "    eeg_data: evoked eeg\n",
    "    tavg_data: evoked raw data\n",
    "    rseeg: resting state eeg\n",
    "    rstavg: resting state raw\n",
    "    nodes:regions of interest\n",
    "    eeg_nodes: sensors of itnerest\n",
    "    time: time vector\n",
    "    \"\"\"\n",
    "\n",
    "    fig_width_pt = 1200.0  # Get this from LaTeX using \\showthe\\columnwidth\n",
    "    inches_per_pt = 1.0 / 72.27               # Convert pt to inch\n",
    "    golden_mean = (numpy.sqrt(5) + 1.0) / 2.0         # Aesthetic ratio\n",
    "    fig_width = fig_width_pt * inches_per_pt  # width in inches\n",
    "    fig_height = fig_width * golden_mean      # height in inches\n",
    "    fig_size = [fig_height, fig_width]\n",
    "    params = {'backend': 'ps',\n",
    "              'axes.labelsize': 26,\n",
    "              'text.fontsize': 20,\n",
    "              'legend.fontsize': 30,\n",
    "              'xtick.labelsize': 24,\n",
    "              'ytick.labelsize': 24,\n",
    "              'text.usetex': True,\n",
    "              'figure.figsize': fig_size}\n",
    "    pyplot.rcParams.update(params)\n",
    "    pyplot.locator_params(axis='y', nbins=4)\n",
    "\n",
    "    # assuming resting state time series\n",
    "    tavg_data = numpy.array(tavg_data)\n",
    "\n",
    "    # assuming evoked activity\n",
    "    eeg_data = numpy.array(eeg_data)\n",
    "\n",
    "    # subsample the stimulus\n",
    "    pattern = pattern[:, ::pattern.shape[1] / eeg_data.shape[0]].T\n",
    "    pattern = pattern[:-1, :]\n",
    "\n",
    "    plot_ts = True\n",
    "    if plot_ts:\n",
    "        figure(1)\n",
    "        # create a nice subplot layout\n",
    "        gs = gridspec.GridSpec(6, 4)\n",
    "\n",
    "        ax1 = subplot(gs[:2, :-1])\n",
    "        ax1z = subplot(gs[:2, -1])\n",
    "\n",
    "        ax0 = subplot(gs[2, :-1])\n",
    "        ax0z = subplot(gs[2, -1])\n",
    "        ax2 = subplot(gs[3:5, :-1])\n",
    "        ax2z = subplot(gs[3:5, -1])\n",
    "\n",
    "        # ER raw traces + stimulation pattern\n",
    "        temp_v2 = tavg_data[start:stop, 0, nodes[1], 0]\n",
    "        temp_v1 = tavg_data[start:stop, 0, nodes[0], 0]\n",
    "\n",
    "        temp_v1 = (temp_v1 - temp_v1.min())\n",
    "        temp_v2 = (temp_v2 - temp_v2.min())\n",
    "\n",
    "        temp_v1 /= abs(temp_v1.max())\n",
    "        temp_v2 /= abs(temp_v2.max())\n",
    "        temp_v2 *= 0.25\n",
    "\n",
    "        temp_v2 += temp_v1.max() + 0.5  # offset for pretty pictures\n",
    "\n",
    "        ## V2-V1 stochastic \n",
    "\n",
    "        ax1.plot(time[start:stop], temp_v2, color='#1C79FC', lw=3, label=\"V2\")\n",
    "        ax1.plot(time[start:stop], temp_v1, 'k', lw=3, label=\"V1\")\n",
    "        ax1.patch.set_facecolor('#1C79FC')\n",
    "        ax1.patch.set_alpha(0.15)\n",
    "        ax1.set_xlim([time[start], time[stop - 1]])\n",
    "        ax1.set_ylim([temp_v1.min() - 0.15, temp_v2.max() + 0.15])\n",
    "\n",
    "        ##  V2-V1 stochastic  - Zoom in \n",
    "        ax1z.plot(time[start:stop // 2], tavg_data[start:stop // 2, 0, nodes[1], 0], color='#1C79FC', lw=3, label=\"V2\")\n",
    "        ax1z.plot(time[start:stop // 2], tavg_data[start:stop // 2, 0, nodes[0], 0], 'k', lw=3, label=\"V1\")\n",
    "        ax1z.patch.set_facecolor('#1C79FC')\n",
    "        ax1z.patch.set_alpha(0.15)\n",
    "        ax1z.axes.get_xaxis().set_visible(False)\n",
    "        ax1z.set_xlabel(\"time (ms)\")\n",
    "\n",
    "        ax1.axes.get_xaxis().set_visible(False)\n",
    "        setp(ax1.get_yticklabels(), visible=False)\n",
    "        ax1.set_ylabel(\"raw traces\")\n",
    "        ax1.set_xlabel(\"time (ms)\")\n",
    "        ax1.legend()\n",
    "\n",
    "        ## pp\n",
    "\n",
    "        ## stimulus pattern\n",
    "        ax0.plot(time[start:stop], pattern[start:stop], 'r', linewidth=3, alpha=0.4, label=\"stim\")\n",
    "        ax0.set_xlim([time[start], time[stop - 1]])\n",
    "        ax0.axes.get_xaxis().set_visible(False)\n",
    "        ax0.set_ylim([-0.1, 1.25])\n",
    "        setp(ax0.get_yticklabels(), visible=False)\n",
    "        ax0.set_ylabel(\"stimulus\")\n",
    "\n",
    "        ##  Stimulus pattern  - Zoom in \n",
    "        ax0z.plot(time[start:stop // 2], 3.5 * pattern[start:stop // 2], 'r', linewidth=3, alpha=0.4, label=\"stim\")\n",
    "        ax0z.axes.get_xaxis().set_visible(False)\n",
    "        ax0z.set_ylim([-0.1, 3.75])\n",
    "\n",
    "        # eeg traces\n",
    "        temp_oz = eeg_data[start:stop, 0, eeg_nodes[2], 0]\n",
    "        temp_o1 = eeg_data[start:stop, 0, eeg_nodes[0], 0]\n",
    "\n",
    "        temp_oz = (temp_oz - temp_oz.min())\n",
    "        temp_o1 = (temp_o1 - temp_o1.min())\n",
    "\n",
    "        temp_oz += temp_o1.max()\n",
    "\n",
    "        ax2.plot(time[start:stop], temp_oz, 'k', lw=2, label=\"OZ\")\n",
    "        ax2.plot(time[start:stop], temp_o1, color='0.55', lw=2, label=\"O1\")\n",
    "        ax2.patch.set_facecolor('red')\n",
    "        ax2.patch.set_alpha(0.10)\n",
    "        ax2.set_xlim([time[start], time[stop - 1]])\n",
    "        ax2.set_ylim([temp_o1.min() - 0.15, temp_oz.max() + 0.15])\n",
    "        ax2.set_xlabel(\"time (ms)\")\n",
    "        setp(ax2.get_yticklabels(), visible=False)\n",
    "        ax2.set_ylabel(\"EEG \")\n",
    "        ax2.legend()\n",
    "\n",
    "        ## zoom in \n",
    "        ax2z.plot(time[start:stop // 2], eeg_data[start:stop // 2, 0, eeg_nodes[2], 0], 'k', lw=2, label=\"OZ\")\n",
    "        ax2z.plot(time[start:stop // 2], eeg_data[start:stop // 2, 0, eeg_nodes[0], 0], color='0.55', lw=2, label=\"O1\")\n",
    "        ax2z.patch.set_facecolor('red')\n",
    "        ax2z.patch.set_alpha(0.1)\n",
    "        ax2z.set_xticks([1000, 1100, 1200])\n",
    "        ax2z.set_xlabel(\"time (ms)\")\n",
    "        show()\n",
    "        #savefig(\"Fig11_sampen_sto.pdf\")\n",
    "\n",
    "    plot_sampen = True\n",
    "    if plot_sampen:\n",
    "        figure(2)\n",
    "        rseeg_data = numpy.array(rseeg)\n",
    "        gs = gridspec.GridSpec(3, 1)\n",
    "\n",
    "        ax0 = subplot(gs[0, :])\n",
    "        ax1 = subplot(gs[1, :])\n",
    "        ax2 = subplot(gs[2, :])\n",
    "\n",
    "        ax0.plot(time[start:stop], rseeg_data[start:stop, 0, eeg_nodes[2], 0], 'k', lw=2, label=\"OZ-RS\")\n",
    "        ax0.set_xlim([time[start], time[stop - 1]])\n",
    "        ax0.set_ylim([-25, 55])\n",
    "        ax0.axes.get_xaxis().set_visible(False)\n",
    "        ax0.patch.set_facecolor('green')\n",
    "        ax0.legend(loc=2)\n",
    "        ax0.patch.set_alpha(0.15)\n",
    "\n",
    "        pattern = (pattern * 8.) - 24.\n",
    "        ax1.plot(time[start:stop], eeg_data[start:stop, 0, eeg_nodes[2], 0], 'k', lw=2, label=\"OZ-ER\")\n",
    "        ax1.plot(time[start:stop], pattern[start:stop], 'k', linewidth=3, alpha=0.4, label=\"stim\")\n",
    "        ax1.set_xlim([time[start], time[stop]])\n",
    "        ax1.set_ylim([-25, 55])\n",
    "        ax1.set_xlabel(\"time [ms]\")\n",
    "        ax1.patch.set_facecolor('blue')\n",
    "        ax1.patch.set_alpha(0.15)\n",
    "        ax1.legend(loc=2)\n",
    "\n",
    "        # sample entropy\n",
    "        ax2.plot(numpy.r_[4:13], se_x, 'k--', label=\"resting state\", linewidth=3)\n",
    "        ax2.plot(numpy.r_[4:13], se_y, 'k', label=\"evoked activity\", linewidth=3)\n",
    "        ax2.set_xlim([4, 12])\n",
    "        ax2.set_ylabel(\"MSE\")\n",
    "        ax2.set_xlabel(\"temporal scale\")\n",
    "        ax2.legend(loc=2)\n",
    "        show()\n",
    "        #savefig(\"Fig12_mse.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # First simulation --> resting state\n",
    "    sim = configure_simulation(stimulate=False)\n",
    "    ts, tt, es, et, _ = run_simulation(sim)\n",
    "\n",
    "    # Second simulation -- > evoked responses\n",
    "    sim_stim = configure_simulation(stimulate=True)\n",
    "    sts, stt, ses, sett, stim = run_simulation(sim_stim)\n",
    "\n",
    "    save_data(sts, ses, stt, sett, stim)\n",
    "\n",
    "    # Analyze --> compute sample entropy\n",
    "    se_x, se_y = compute_mse(es, ses)\n",
    "\n",
    "    # Visualize\n",
    "    pattern = stim.temporal.pattern\n",
    "    plot_figure(se_x, se_y, ses, sts, es, ts, pattern, nodes, eeg_nodes, et)\n",
    "\n",
    "    return LOG.info(\"\"\"Done.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-07-15 11:59:16,140 - WARNING - tvb.basic.readers - File hemispheres not found in ZIP.\n",
      "2015-07-15 12:02:45,394 - WARNING - tvb.basic.readers - File hemispheres not found in ZIP.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
